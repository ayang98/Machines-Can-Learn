{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 12070604186769766662, name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 7386457533402831773\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 1774279613862598936\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 15864515789\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 8397216354946057721\n",
       " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape\n",
    "from keras.layers.core import Layer, Dense, Dropout, Activation, Flatten, Reshape, Permute\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Convolution3D, MaxPooling3D, ZeroPadding3D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam , SGD\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils import np_utils\n",
    "# from keras.regularizers import ActivityRegularizer\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy as np\n",
    "from keras.layers import Dense,Lambda\n",
    "\n",
    "\n",
    "smooth = 1e-9\n",
    "\n",
    "# This is the competition metric implemented using Keras\n",
    "def dice_coef(y_true, y_pred):\n",
    "  \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * (K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "# We'll construct a Keras Loss that incorporates the DICE score\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1. - (2. * intersection + 1.) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "\n",
    "    return 0.5 * binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\"\"\"\n",
    "# Create simple model\n",
    "from keras.layers import Conv2D, Reshape\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, 5, activation='relu', padding='same', input_shape=(128, 128, 3)))\n",
    "model.add(Conv2D(128, 5, activation='relu', padding='same'))\n",
    "model.add(Conv2D(1, 5, activation='sigmoid', padding='same'))\n",
    "model.add(Reshape((128, 128)))\n",
    "          \n",
    "model.compile(Adam(lr=0.01), loss=bce_dice_loss, metrics=[dice_coef])     \n",
    "\"\"\"\n",
    "def segnet(nClasses, input_height=512, input_width=512):\n",
    "\n",
    "    kernel = 3\n",
    "    filter_size = 64\n",
    "    pad = 1\n",
    "    pool_size = 2\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Layer(input_shape=(input_height , input_width,3)))\n",
    "\n",
    "    # encoder\n",
    "    model.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add(Convolution2D(filter_size, kernel, kernel, border_mode='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add(Convolution2D(128, kernel, kernel, border_mode='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add(Convolution2D(256, kernel, kernel, border_mode='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "    model.add(ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add(Convolution2D(512, kernel, kernel, border_mode='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "\n",
    "\n",
    "    # decoder\n",
    "    model.add( UpSampling2D(size=(pool_size,pool_size)))\n",
    "    model.add( ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add( Convolution2D(512, kernel, kernel, border_mode='valid'))\n",
    "    model.add( BatchNormalization())\n",
    "\n",
    "    model.add( UpSampling2D(size=(pool_size,pool_size)))\n",
    "    model.add( ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add( Convolution2D(256, kernel, kernel, border_mode='valid'))\n",
    "    model.add( BatchNormalization())\n",
    "\n",
    "    model.add( UpSampling2D(size=(pool_size,pool_size)))\n",
    "    model.add( ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add( Convolution2D(128, kernel, kernel, border_mode='valid'))\n",
    "    model.add( BatchNormalization())\n",
    "\n",
    "    model.add( UpSampling2D(size=(pool_size,pool_size)))\n",
    "    model.add( ZeroPadding2D(padding=(pad,pad)))\n",
    "    model.add( Convolution2D(filter_size, kernel, kernel, border_mode='valid'))\n",
    "    model.add( BatchNormalization())\n",
    "\n",
    "\n",
    "    model.add(Convolution2D( nClasses , 1, 1, border_mode='valid',))\n",
    "    \n",
    "    model.outputHeight = model.output_shape[-2]\n",
    "    model.outputWidth = model.output_shape[-1]\n",
    "\n",
    "    #model.add(Reshape((model.output_shape[-2]*model.output_shape[-1], nClasses), input_shape=(model.output_shape[-2], model.output_shape[-1]  )))\n",
    "    #model.add(Permute((2, 1)))\n",
    "    model.add(Activation('softmax'))\n",
    "    #model.add(Lambda(lambda x: K.argmax(x)))\n",
    "    #model.add(Lambda(lambda x: K.cast(x,\"int\")))\n",
    "    #if not optimizer is None:\n",
    "    model.compile(Adam(lr=1e-3), loss=bce_dice_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "import os\n",
    "import sys\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import *\n",
    "from keras.engine import Layer\n",
    "from keras.applications.vgg16 import *\n",
    "from keras.models import *\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def FCN_Vgg16_32s(input_shape=None, weight_decay=0., batch_momentum=0.9, batch_shape=None, classes=2):\n",
    "    if batch_shape:\n",
    "        img_input = Input(batch_shape=batch_shape)\n",
    "        image_size = batch_shape[1:3]\n",
    "    else:\n",
    "        img_input = Input(shape=input_shape)\n",
    "        image_size = input_shape[0:2]\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', kernel_regularizer=l2(weight_decay))(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    # Convolutional layers transfered from fully-connected layers\n",
    "    x = Conv2D(256, (7, 7), activation='relu', padding='same', name='fc1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv2D(256, (1, 1), activation='relu', padding='same', name='fc2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv2D(128, (7, 7), activation='relu', padding='same', name='fc3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv2D(128, (1, 1), activation='relu', padding='same', name='fc4', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv2D(64, (7, 7), activation='relu', padding='same', name='fc5', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu', padding='same', name='fc6', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #classifying layer\n",
    "    x = Conv2D(classes, (1, 1), kernel_initializer='he_normal', activation='linear', padding='valid', strides=(1, 1), kernel_regularizer=l2(weight_decay))(x)\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (x)\n",
    "   \n",
    "\n",
    "    model = Model(img_input, outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train/10729_sat.jpg', 'train/51187_sat.jpg', 'train/52299_sat.jpg', 'train/4962_sat.jpg', 'train/13549_sat.jpg', 'train/15363_sat.jpg', 'train/38456_sat.jpg', 'train/50517_sat.jpg', 'train/32252_sat.jpg', 'train/12993_sat.jpg']\n",
      "['train/12895_msk.png', 'train/23379_msk.png', 'train/19799_msk.png', 'train/2575_msk.png', 'train/50807_msk.png', 'train/41694_msk.png', 'train/9457_msk.png', 'train/34365_msk.png', 'train/47347_msk.png', 'train/21599_msk.png']\n",
      "['val/70036_sat.jpg', 'val/75729_sat.jpg', 'val/78249_sat.jpg', 'val/76288_sat.jpg', 'val/71029_sat.jpg']\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "path_to_train = 'train'\n",
    "glob_train_imgs = os.path.join(path_to_train, '*_sat.jpg')\n",
    "glob_train_masks = os.path.join(path_to_train, '*_msk.png')\n",
    "\n",
    "train_img_paths = glob(glob_train_imgs)\n",
    "train_mask_paths = glob(glob_train_masks)\n",
    "print(train_img_paths[:10])\n",
    "print(train_mask_paths[:10])\n",
    "\n",
    "\n",
    "path_to_val = 'val'\n",
    "glob_val_imgs = os.path.join(path_to_val, '*_sat.jpg')\n",
    "val_img_paths = glob(glob_val_imgs)\n",
    "print(val_img_paths[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "# This will be useful so we can construct the corresponding mask\n",
    "def get_img_id(img_path):\n",
    "    img_basename = os.path.basename(img_path)\n",
    "    img_id = os.path.splitext(img_basename)[0][:-len('_sat')]\n",
    "    return img_id\n",
    "\n",
    "# Write it like a normal function\n",
    "def image_gen(img_paths, img_size=(512, 512)):\n",
    "    # Iterate over all the image paths\n",
    "    for img_path in img_paths:\n",
    "        \n",
    "        # Construct the corresponding mask path\n",
    "        img_id = get_img_id(img_path)\n",
    "        mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
    "        \n",
    "        # Load the image and mask, and normalize it to 0-1 range\n",
    "        img = imread(img_path) #/ 255.\n",
    "        mask = rgb2gray(imread(mask_path))\n",
    "        \n",
    "        # Resize the images\n",
    "        img = resize(img, img_size, preserve_range=True)\n",
    "        mask = resize(mask, img_size, mode='constant', preserve_range=True)\n",
    "        # Turn the mask back into a 0-1 mask\n",
    "        mask = (mask >= 0.5).astype(float)\n",
    "        \n",
    "        # Yield the image mask pair\n",
    "        yield img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 512, 512, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 512, 512, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "fc1 (Conv2D)                 (None, 16, 16, 256)       6422784   \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "fc2 (Conv2D)                 (None, 16, 16, 256)       65792     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "fc3 (Conv2D)                 (None, 16, 16, 128)       1605760   \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "fc4 (Conv2D)                 (None, 16, 16, 128)       16512     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "fc5 (Conv2D)                 (None, 16, 16, 64)        401472    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "fc6 (Conv2D)                 (None, 16, 16, 64)        4160      \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_267 (Conv2D)          (None, 16, 16, 2)         130       \n",
      "_________________________________________________________________\n",
      "conv2d_268 (Conv2D)          (None, 16, 16, 1)         3         \n",
      "=================================================================\n",
      "Total params: 23,231,301\n",
      "Trainable params: 23,231,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = FCN_Vgg16_32s((512,512,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute average image\n",
    "\n",
    "average = np.empty((512,512,3))\n",
    "for i in range(len(train_img_paths)):\n",
    "    img = imread(train_img_paths[i])\n",
    "    average = np.add(average, img)\n",
    "average = average/10897"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute standard deviation image\n",
    "\n",
    "sd = np.empty((512,512,3))\n",
    "for i in range(len(train_img_paths)):\n",
    "    img = imread(train_img_paths[i])\n",
    "    a = np.subtract(img, average)\n",
    "    a = np.square(a)\n",
    "    sd = np.add(sd, a)\n",
    "sd = sd/10897\n",
    "sd = np.sqrt(sd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 40.41082667  32.25589746  30.80810358]\n",
      "  [ 40.07896065  31.89023177  30.40830101]\n",
      "  [ 40.39878584  32.33384431  30.82290725]\n",
      "  ..., \n",
      "  [ 40.47686276  32.31425617  30.78016282]\n",
      "  [ 40.42960732  32.20080082  30.6607908 ]\n",
      "  [ 40.61248159  32.3660722   30.8595762 ]]\n",
      "\n",
      " [[ 40.12767114  32.06398593  30.56245447]\n",
      "  [ 39.87489401  31.82907065  30.3692613 ]\n",
      "  [ 40.15589891  32.13324647  30.62535854]\n",
      "  ..., \n",
      "  [ 40.14705256  32.01550519  30.50772375]\n",
      "  [ 40.09326625  31.87761547  30.37449059]\n",
      "  [ 40.25014628  31.99787813  30.47001007]]\n",
      "\n",
      " [[ 40.18354043  32.18617777  30.5820286 ]\n",
      "  [ 39.94309981  31.95973407  30.40409358]\n",
      "  [ 40.15804531  32.19126586  30.60119408]\n",
      "  ..., \n",
      "  [ 40.27019059  32.1806527   30.61388328]\n",
      "  [ 40.19098308  32.03460514  30.45726627]\n",
      "  [ 40.38486663  32.21967474  30.64666009]]\n",
      "\n",
      " ..., \n",
      " [[ 40.38854176  32.27642034  30.37098629]\n",
      "  [ 40.2094635   32.10089655  30.21412687]\n",
      "  [ 40.39702093  32.39041923  30.54226738]\n",
      "  ..., \n",
      "  [ 39.95118094  31.85077672  30.10270294]\n",
      "  [ 39.84252585  31.70418948  30.03977583]\n",
      "  [ 39.93393511  31.86806601  30.24602122]]\n",
      "\n",
      " [[ 40.29020561  32.17502005  30.41473144]\n",
      "  [ 40.17423547  32.07175077  30.34450712]\n",
      "  [ 40.2770336   32.2324922   30.50567214]\n",
      "  ..., \n",
      "  [ 39.92311763  31.806927    30.01586134]\n",
      "  [ 39.74283173  31.54764563  29.80114701]\n",
      "  [ 39.84520556  31.64623732  29.95186106]]\n",
      "\n",
      " [[ 40.38272267  32.2306328   30.49319261]\n",
      "  [ 40.23335487  32.13845331  30.47983097]\n",
      "  [ 40.32305624  32.32918354  30.64372484]\n",
      "  ..., \n",
      "  [ 40.23377021  32.17213433  30.4264833 ]\n",
      "  [ 40.03199925  31.87537903  30.14617102]\n",
      "  [ 40.34444478  32.11302058  30.36118251]]]\n"
     ]
    }
   ],
   "source": [
    "print (sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Keras takes its input in batches \n",
    "# (i.e. a batch size of 32 would correspond to 32 images and 32 masks from the generator)\n",
    "# The generator should run forever\n",
    "def image_batch_generator(img_paths, batchsize=32):\n",
    "    while True:\n",
    "        ig = image_gen(img_paths)\n",
    "        batch_img, batch_mask = [], []\n",
    "        \n",
    "        for img, mask in ig:\n",
    "            # Add the image and mask to the batch\n",
    "            img = np.divide((img - average),sd) #0 mean, 1 var\n",
    "            batch_img.append(img)\n",
    "            batch_mask.append(mask)\n",
    "            # If we've reached our batchsize, yield the batch and reset\n",
    "            if len(batch_img) == batchsize:\n",
    "                yield np.stack(batch_img, axis=0), np.stack(batch_mask, axis=0)\n",
    "                batch_img, batch_mask = [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-8f684201f027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Change this number based on memory restrictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m )\n",
      "\u001b[0;32m/jet/var/python/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jet/var/python/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jet/var/python/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jet/var/python/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    497\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    499\u001b[0m                 updates = (self.updates +\n\u001b[1;32m    500\u001b[0m                            \u001b[0mtraining_updates\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jet/var/python/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jet/var/python/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_updates_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/jet/var/python/lib/python3.6/site-packages/keras/optimizers.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             raise ValueError('An operation has `None` for gradient. '\n\u001b[0m\u001b[1;32m     92\u001b[0m                              \u001b[0;34m'Please make sure that all of your ops have a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                              \u001b[0;34m'gradient defined (i.e. are differentiable). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import keras.callbacks\n",
    "BATCHSIZE = 32\n",
    "\n",
    "# Split the data into a train and validation set\n",
    "train_img_paths, val_img_paths = train_test_split(train_img_paths, test_size=0.15)\n",
    "\n",
    "# Create the train and validation generators\n",
    "traingen = image_batch_generator(train_img_paths, batchsize=BATCHSIZE)\n",
    "valgen = image_batch_generator(val_img_paths, batchsize=BATCHSIZE)\n",
    "\n",
    "def calc_steps(data_len, batchsize):\n",
    "    return (data_len + batchsize - 1) // batchsize\n",
    "\n",
    "# Calculate the steps per epoch\n",
    "train_steps = calc_steps(len(train_img_paths), BATCHSIZE)\n",
    "val_steps = calc_steps(len(val_img_paths), BATCHSIZE)\n",
    "\n",
    "filepath=\"unet.hdf5\"\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=0, save_best_only=False, save_weights_only=True, mode='auto', period=1)\n",
    "callbacks_list = [checkpoint]\n",
    "# Train the model\n",
    "history = model.fit_generator(\n",
    "    traingen, \n",
    "    steps_per_epoch=train_steps, \n",
    "    epochs= 20, # Change this to a larger number to train for longer\n",
    "    validation_data=valgen, \n",
    "    validation_steps=val_steps, \n",
    "    verbose=1,\n",
    "    max_queue_size=5, # Change this number based on memory restrictions\n",
    "    callbacks = callbacks_list \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create submission DataFrame\n",
    "def create_submission(csv_name, predictions_gen):\n",
    "    \"\"\"\n",
    "    csv_name -> string for csv (\"XXXXXXX.csv\")\n",
    "    predictions -> generator that yields a pair of id, prediction\n",
    "    \"\"\"\n",
    "    sub = pd.DataFrame()\n",
    "    ids = []\n",
    "    encodings = []\n",
    "    num_images = len(val_img_paths)\n",
    "    for i in range(num_images):\n",
    "        if (i+1) % (num_images//10) == 0:\n",
    "            print(i, num_images)\n",
    "        img_id, pred = next(predictions_gen)\n",
    "        ids.append(img_id)\n",
    "        #print (np.count_nonzero(pred == 1))\n",
    "        encodings.append(rle_encoding(pred))\n",
    "        \n",
    "    sub['EncodedPixels'] = encodings\n",
    "    sub['ImageId'] = ids\n",
    "    sub.to_csv(csv_name, index=False)\n",
    "\n",
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    \"\"\"\n",
    "    x = numpyarray of size (height, width) representing the mask of an image\n",
    "    if x[i,j] == 0:\n",
    "        image[i,j] is not a road pixel\n",
    "    if x[i,j] != 0:\n",
    "        image[i,j] is a road pixel\n",
    "    \"\"\"\n",
    "    dots = np.where(x.T.flatten() != 0)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): \n",
    "            run_lengths.extend((b+1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_pixel_by_pixel_predictions_generator(val_paths):\n",
    "    for img_path in val_paths:        \n",
    "        img = imread(img_path)\n",
    "        img = resize(img, (512, 512), preserve_range=True) \n",
    "        img = np.divide((img - average),sd) #0 mean, 1 var\n",
    "        y = model.predict(img.reshape(1,512,512,3))  \n",
    "        y = (y >= 0.5).astype(float) #IMPORTANT- need this or you won't have 0 or 1 (because outputs are probabilities!!)\n",
    "        yield get_img_id(img_path), y.reshape(512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215 2169\n",
      "431 2169\n",
      "647 2169\n",
      "863 2169\n",
      "1079 2169\n",
      "1295 2169\n",
      "1511 2169\n",
      "1727 2169\n",
      "1943 2169\n",
      "2159 2169\n",
      "119.65486407279968\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "path_to_train = 'train'\n",
    "glob_train_imgs = os.path.join(path_to_train, '*_sat.jpg')\n",
    "glob_train_masks = os.path.join(path_to_train, '*_msk.png')\n",
    "train_img_paths = glob(glob_train_imgs)\n",
    "path_to_val = 'val'\n",
    "glob_val_imgs = os.path.join(path_to_val, '*_sat.jpg')\n",
    "val_img_paths = glob(glob_val_imgs)\n",
    "\n",
    "\n",
    "#first_img, first_mask = next(ig)\n",
    "\"\"\"\n",
    "img_size = (128,128)\n",
    "for i in range(30,50): \n",
    "    \n",
    "    img_id = get_img_id(train_img_paths[i])\n",
    "    mask_path = os.path.join(path_to_train, img_id + '_msk.png')\n",
    "           \n",
    "    img = imread(train_img_paths[i]) / 255.\n",
    "    mask = rgb2gray(imread(mask_path))\n",
    "    img = resize(img, img_size, preserve_range=True)\n",
    "    mask = resize(mask, img_size, mode='constant', preserve_range=True)    \n",
    "    mask = (mask >= 0.5).astype(float)\n",
    "    \n",
    "    plt.imshow(mask, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    y = model.predict(img.reshape(1,128,128,3)) \n",
    "    y = (y.reshape(128,128) >= 0.5).astype(float)\n",
    "    \n",
    "    plt.imshow(y, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    img = imread(val_img_paths[i]) / 255.\n",
    "    img = resize(img, (128, 128), preserve_range=True)  \n",
    "    print (get_img_id(val_img_paths[i]))\n",
    "    y = model.predict(img.reshape(1,128,128,3)) \n",
    "    y = (y >= 0.5).astype(float)\n",
    "    #print (np.count_nonzero(y == 1))\n",
    "    #print (y)\n",
    "    plt.imshow(y.reshape(128,128), cmap='gray')\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "tic = time.time()\n",
    "create_submission(\"unet.csv\", generate_pixel_by_pixel_predictions_generator(val_img_paths))\n",
    "toc = time.time()\n",
    "print(toc - tic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e109086d57c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dice_coef'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_dice_coef'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Dice\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEICAYAAACeSMncAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "# Plot the training curve\n",
    "pd.DataFrame(history.history)[['loss', 'val_loss']].plot(title=\"Loss\", logy=True)\n",
    "pd.DataFrame(history.history)[['dice_coef', 'val_dice_coef']].plot(title=\"Dice\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
