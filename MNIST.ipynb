{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This neural network has one input layer, two hidden layers, and one output layer with 10 neurons (10 possible classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28,28)),\n",
    "    keras.layers.Dense(512, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images[0]) #plot the image matrix\n",
    "#print(train_labels[0])\n",
    "#print(train_images[0])\n",
    "train_images  = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.3681 - acc: 0.8700\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3550 - acc: 0.8725\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.3426 - acc: 0.8784\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.3323 - acc: 0.8821\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.3222 - acc: 0.8842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x288aad7e198>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'sgd',\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 68us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.405930677819252, 0.8529]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.4031640e-05 1.0506518e-05 8.3932355e-05 8.3925712e-05 2.7185979e-05\n",
      " 9.0393879e-02 1.6727175e-04 1.3038118e-01 9.5356898e-03 7.6928246e-01]\n",
      "[9 2 1 ... 8 1 5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifications = model.predict(test_images)\n",
    "\n",
    "plt.imshow(test_images[0]) #plot the image matrix\n",
    "\n",
    "print(classifications[0])\n",
    "\n",
    "print (np.argmax(classifications, axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code for callback- ending the training before the number of specified epochs once convergence is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.4720\n",
      "Epoch 2/5\n",
      "59808/60000 [============================>.] - ETA: 0s - loss: 0.3594\n",
      "Reached 60% accuracy so cancelling training!\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.3592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28b27f47c18>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss')<0.4):\n",
    "            print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0]) #plot the image matrix\n",
    "print(y_train[0])\n",
    "print(x_train[0])\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28,28)),\n",
    "    keras.layers.Dense(512, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 29s 484us/step - loss: 0.1842 - acc: 0.9441\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 27s 457us/step - loss: 0.0801 - acc: 0.9756\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 40s 665us/step - loss: 0.0560 - acc: 0.9819\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 42s 694us/step - loss: 0.0420 - acc: 0.9869\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 29s 491us/step - loss: 0.0350 - acc: 0.9884\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 28s 461us/step - loss: 0.0285 - acc: 0.9908\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 23s 381us/step - loss: 0.0246 - acc: 0.99201s - loss:\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 19s 310us/step - loss: 0.0245 - acc: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28b2950eb38>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 86us/step\n",
      "[3.8628494e-17 2.3186971e-11 6.5148620e-12 4.6751412e-11 1.0875046e-14\n",
      " 3.5863209e-14 5.5464998e-19 1.0000000e+00 2.4628766e-13 2.1654692e-10]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "classifications = model.predict(x_test)\n",
    "\n",
    "plt.imshow(x_test[0]) #plot the image matrix\n",
    "\n",
    "print(classifications[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion MNIST CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "(60000, 28, 28)\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 172s 3ms/step - loss: 0.3765 - acc: 0.8628\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.2547 - acc: 0.9064\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 150s 2ms/step - loss: 0.2035 - acc: 0.9227\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.1674 - acc: 0.9362\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 129s 2ms/step - loss: 0.1361 - acc: 0.9488\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 137s 2ms/step - loss: 0.1139 - acc: 0.9564\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 177s 3ms/step - loss: 0.0949 - acc: 0.9649\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0812 - acc: 0.9698 0s - loss: 0.0812 - acc:\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 126s 2ms/step - loss: 0.0658 - acc: 0.9750\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0596 - acc: 0.9782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b003f38fd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "class myCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc')>0.998):\n",
    "            print(\"\\nReached 99.8% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "mnist = keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images=training_images/255.0\n",
    "test_images=test_images/255.0\n",
    "\n",
    "print (training_images.shape)\n",
    "model = keras.models.Sequential([    \n",
    "    keras.layers.Conv2D(64,(4,4), activation = 'relu', input_shape = (28,28,1)),  #Conv2D expects input with 4 dimensions so add extra 1\n",
    "    keras.layers.MaxPooling2D((2,2), strides = 2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "training_images = training_images.reshape(60000, 28, 28, 1) #reshape input training data to 4 dimensions \n",
    "\n",
    "model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s 904us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42551467752978206, 0.9095]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = test_images.reshape(10000, 28, 28, 1) #test data also reshaped to 4 dimensions since Conv2D used in model\n",
    "model.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
